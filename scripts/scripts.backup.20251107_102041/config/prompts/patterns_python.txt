## PYTHON-SPECIFIC VIOLATION PATTERNS - ZERO TOLERANCE

### CRITICAL

**Ruff Exemption Abuse**: Adding exemptions to `ruff.toml` instead of fixing code quality issues
- **Violation Codes (ALL FORBIDDEN)**:
  - **PLC0415**: Lazy imports (import inside function) - refactor to top-level imports
  - **C901**: Function too complex (>10 complexity) - decompose into smaller functions
  - **PLR0911**: Too many returns (>6) - consolidate logic, use early returns properly
  - **PLR0912**: Too many branches (>16) - extract decision logic into separate functions
  - **PLR0915**: Too many statements (>96) - split into multiple focused functions
  - **PLR0913**: Too many arguments (>30) - use config objects or dataclasses
  - **S603**: subprocess without shell=False - add explicit shell=False
  - **S607**: subprocess with partial path - use absolute paths or shutil.which()
  - **S110**: try/except pass - log errors or handle properly, never silently swallow
  - **ARG001/ARG002**: Unused arguments - remove or use them, don't ignore
  - **SIM108**: Use ternary operator - simplify if/else to ternary
  - **N806**: Variable naming - fix to lowercase_with_underscores
  - **PTH123**: open() instead of Path.open() - use pathlib properly
  - **PLR2004**: Magic numbers - extract to named constants
  - **SIM115**: Use context manager - wrap file operations in with statements
  - **B007**: Unused loop variable - use _ or fix logic
  - **ERA001**: Commented code - delete or uncomment, don't leave dead code
  - **B018**: Useless expression - remove or assign to variable
  - **B023**: Closure variable binding - fix loop variable capture
- **Example VIOLATIONS**:
  ```python
  # WRONG - Adding exemption instead of fixing:
  "myfile.py" = ["C901", "PLR0911", "PLC0415"]  # Complex function, many returns, lazy imports

  # WRONG - Lazy import to hide dependencies:
  def my_function():
      import expensive_module  # PLC0415 violation
      return expensive_module.do_thing()

  # WRONG - Overly complex function:
  def process_data(data):  # C901 - complexity 25
      if condition1:
          if condition2:
              if condition3:
                  if condition4:
                      # ... 50 more lines

  # WRONG - Too many return paths:
  def validate(data):  # PLR0911 - 12 returns
      if not data: return False
      if not data.field1: return False
      if not data.field2: return False
      # ... 9 more returns
  ```
- **CORRECT APPROACH**:
  ```python
  # CORRECT - Fix the code, don't add exemptions:

  # Top-level imports (fixes PLC0415):
  import expensive_module

  def my_function():
      return expensive_module.do_thing()

  # Extract complexity (fixes C901):
  def process_data(data):
      if not _validate_conditions(data):
          return None
      return _perform_processing(data)

  def _validate_conditions(data):
      return condition1 and condition2 and condition3

  # Consolidate returns (fixes PLR0911):
  def validate(data):
      required_fields = [data, data.field1, data.field2, ...]
      return all(required_fields)
  ```
- **Why CRITICAL**:
  - Hides technical debt and code smell
  - Makes codebase unmaintainable over time
  - Bypasses quality standards that protect production
  - Creates precedent for more exemption abuse
  - Prevents automated quality enforcement
- **DETECTION**: Any Edit to `ruff.toml` adding codes PLC0415, C901, PLR*, S603, S607, S110, ARG*, SIM*, N806, PTH123, B007, ERA001, B018, B023
- **ZERO TOLERANCE**: Instant rejection - fix the code, never add exemptions

**SQL Injection**: `query = f"SELECT * FROM {var}"` | `cursor.execute(f"...")`

**Subprocess RCE**: `subprocess.run(untrusted)` with fallback chains

**Plain Sensitive Data**: `field: str` for credentials/tokens (use `SecretStr`)

**Crypto Verify → Bool**: `def verify(): compare(); return bool` - hides failures

**Suppression Without Justification**: `# noqa`, `# type: ignore`, `# pylint: disable`, `# mypy: ignore-errors`, `# fmt: off`, `# ruff: noqa`, `# pragma: no cover` WITHOUT multi-line justification
- **ALLOWED**: `# noqa: E402` on import lines in `**/module_setup.py`, `**/run_tests.py`, `scripts/**/*.py` (E402 = module import not at top; these files MUST do path discovery before imports)
- **ALLOWED**: `# type: ignore[<error-code>]  # <library-name>: <reason>` (third-party type stub issue)
- **Example NOT A VIOLATION**:
  ```python
  # In ux/module_setup.py:
  import sys  # noqa: E402  ← CORRECT - required for path discovery
  import os   # noqa: E402  ← CORRECT - required for path discovery
  ```
- **Example VIOLATION**:
  ```python
  # In src/main.py:
  result = dangerous_call()  # type: ignore  ← VIOLATION - needs justification
  ```
- **IMPORTANT**: Don't confuse inline `# noqa: E402` markers (required on specific lines) with file-level exemption configs. Both used together: file-level exempts file, inline marks specific violating lines

**Config Exemption Without Justification**: ADDING to exemption lists (ruff.toml, mypy.ini, etc.) without comment explaining:
  1. Why exemption needed
  2. What rules violated
  3. Why can't fix (architectural constraint)
  4. When/how to remove
  5. Alternatives rejected
- **REMOVING exemptions always allowed**
- Required format:
  ```python
  # file.py: E402 (module import not at top)
  # Reason: path discovery before imports
  # Cannot fix: architectural requirement
  # Removal: when paths refactored
  # Alternatives: PYTHONPATH (fragile), __init__ (not package)
  Path("file.py"),
  ```

**Config File Additions Without Precedent**: ADDING entries to ruff.toml/pyproject.toml/mypy.ini when NO existing precedent
- **VIOLATION Example** (ruff.toml when no other single-file entries exist):
  ```toml
  "scripts/automation/**/*.py" = ["T201", "S603"]  # Existing pattern
  "scripts/automation/audit.py" = ["C901"]  # WRONG - no other single-file entries
  ```
- **CORRECT Approach**: Refactor `_audit_file()` to reduce complexity instead of adding C901 exception
- **ALLOWED**: Adding to existing patterns that match: `"scripts/automation/audit.py" = ["T201", "S603"]` (matches `**/*.py` pattern)
- **FIX CODE instead of config - refactor complex functions, remove prints, fix security**
- **REMOVING config entries always allowed**

**Assert in Production**: `assert condition, "msg"` for validation (disabled with `python -O`)
- **ALLOWED**: Test files only
- **FIX**: `if not condition: raise ValueError("msg")`

**Missing Type Hints**: Functions/methods without type hints; using `Any` instead of concrete types; untyped collections (`dict`, `list`) instead of generic (`dict[str, int]`, `list[str]`)
- **VIOLATION**: `Any` without inline comment justification
- **Example VIOLATION**:
  ```python
  def process_data(config: Any, items: Any) -> Any:  # VIOLATION - no justification
      return results
  ```
- **Example ALLOWED**:
  ```python
  def process_response(data: Any) -> dict[str, Any]:  # Any: boto3 DynamoDB returns untyped nested dicts
      return transform(data)
  ```
- **Correct approach**: Use concrete types; `dict[str, Any]` not bare `dict`; `from __future__ import annotations` for forward refs; `TypeVar`, `Protocol`, `TypedDict` for complex types; inline comment justifying each `Any`

**@dataclass Instead of Pydantic**: ADDING `@dataclass` in production code
- **Example VIOLATION**:
  ```python
  from dataclasses import dataclass

  @dataclass
  class UserConfig:  # VIOLATION - use Pydantic BaseModel
      name: str
      email: str
  ```
- **Required fix**:
  ```python
  from pydantic import BaseModel, Field

  class UserConfig(BaseModel):
      name: str
      email: str

      class Config:
          arbitrary_types_allowed = True
  ```
- **IMPORTANT**: REMOVING dataclasses (converting to Pydantic) ALWAYS allowed and encouraged
- **Correct approach**: Use Pydantic BaseModel for all data models; use Field() for descriptions; add Config with arbitrary_types_allowed for Path types

**Complex Return Types Instead of Pydantic**:
- **VIOLATIONS**: `tuple[str, list[dict]]`, `tuple[str, list[dict[str, str]]]`, `dict[str, str|int]`, `tuple[str, int, bool]` (3+), nested structures
- **ALLOWED**: `tuple[str, int]` (2 simple types), `list[str]`, `dict[str, int]`, `str|None`, simple built-ins (`str`, `int`, `bool`, `Path`)
- **VIOLATION Example**:
  ```python
  def parse(input: str) -> tuple[str, list[dict[str, Any]]]:  # WRONG
      return "success", [{"id": 1}]
  ```
- **FIX Example**:
  ```python
  from pydantic import BaseModel
  class ParseResult(BaseModel):
      status: str
      items: list[dict[str, Any]]
  def parse(input: str) -> ParseResult:  # CORRECT
      return ParseResult(status="success", items=[{"id": 1}])
  ```

**Complex Nested Dict Type Annotations**: `dict[str, dict[...]]`, `dict[str, list[dict[...]]]`, `list[dict[str, dict[...]]]`
- **VIOLATIONS**: Nested dict type annotations are unmaintainable and self-documenting
- **Example VIOLATION**:
  ```python
  self._metadata_cache: dict[str, dict[str, str]] = {}
  self._versions_cache: dict[str, list[str]] = {}
  data: dict[str, list[dict[str, Any]]] = {}
  ```
- **Required fix**:
  ```python
  from pydantic import BaseModel

  class MetadataEntry(BaseModel):
      version: str
      author: str
      # ... other fields with clear names

  self._metadata_cache: dict[str, MetadataEntry] = {}
  ```
- **Why Pydantic models required**: Self-documenting field names, runtime validation, maintainable schema evolution, clear structure for testing/mocking, readable repr() output
- **IMPORTANT**: Converting complex dict annotations to Pydantic models ALWAYS allowed and encouraged

### HIGH

**Import Suppression**: `try: import X; except: continue`

**Lazy Imports**: Import inside function/method bodies instead of module top-level
- **Example VIOLATION**:
  ```python
  def process_data():
      from pathlib import Path  # VIOLATION
      from .config import get_config  # VIOLATION
      return Path("/tmp")
  ```
- **Required fix**:
  ```python
  from pathlib import Path
  from scripts.automation.config import get_config

  def process_data():
      return Path("/tmp")
  ```
- **ALLOWED**: Only with extensive multi-line justification explaining why architecturally required (circular dependency cannot refactor, optional heavy dependency must defer)
- **IMPORTANT**: REMOVING lazy imports (moving to top-level) ALWAYS allowed and encouraged, even if have justification
- **Correct approach**: All imports at module top-level; use `TYPE_CHECKING` guard for type-only imports; refactor circular dependencies

**Relative Imports**: Using relative dot notation (`from .module` or `from ..package.module`)
- **Example VIOLATION**:
  ```python
  from .config import get_config  # VIOLATION
  from .logger import get_logger  # VIOLATION
  from ..utils import helper  # VIOLATION
  ```
- **Required fix**:
  ```python
  from scripts.automation.config import get_config
  from scripts.automation.logger import get_logger
  from scripts.utils import helper
  ```
- **ALLOWED**: NEVER - all imports must be absolute
- **IMPORTANT**: REMOVING relative imports (converting to absolute) ALWAYS allowed and encouraged

**contextlib.suppress**: `with suppress(Exception): risky()`

**Missing Exception Import**: `raise CustomError()` - never imported

**Uncaught HTTP Exception**: `response.raise_for_status()` - no try/except

**User Input Without Validation**: `input = getpass(); use(input)`

**Subprocess Exit Ignored**: `subprocess.run(cmd, check=False)` or `subprocess.call(cmd)`
- **EXCEPTION**: Polyglot shebang wrappers using `exec` command (NOT subprocess)
- **Example NOT A VIOLATION**:
  ```bash
  #!/usr/bin/env bash
  ''':'
  exec "$(dirname "$0")/scripts/ami-run.sh" "$0" "$@"
  '''
  ```
- **Rationale**: `exec` replaces current process (no subprocess created, no exit code to check); standard wrapper pattern; used by pipx, poetry, and other Python tools

**`from __future__` Import Placement with Polyglot Shebang**:
- **REQUIRED**: In files with polyglot shebangs, `from __future__ import annotations` MUST come on line 3 (immediately after shebang), with module docstring on line 4+
- **Example CORRECT**:
  ```python
  #!/usr/bin/env bash
  'exec "$(dirname "$0")/../../scripts/ami-run.sh" "$0" "$@" #'
  from __future__ import annotations

  """Module docstring explaining what this module does."""
  ```
- **Rationale**: Python requires `from __future__` before all code except comments/docstrings. Polyglot shebangs are bash code (not Python comments), so future import must come first. This satisfies both ruff F404 and PEP 257.

**Direct Subprocess Calls**: `subprocess.run([...])`, `subprocess.Popen([...])` outside /base workers
- **Example VIOLATION**:
  ```python
  import subprocess
  result = subprocess.run(["git", "init", "--bare", str(path)], capture_output=True)
  result = subprocess.run(["systemctl", "status", "service"], capture_output=True)
  ```
- **Required fix**:
  ```python
  from base.backend.workers.git_command import GitCommandWorker
  from base.backend.workers.system_command import SystemCommandWorker

  git_worker = GitCommandWorker()
  git_worker.init_bare_repo(path)

  system_worker = SystemCommandWorker()
  system_worker.run_systemctl("status", "service")
  ```
- **IMPORTANT**: All subprocess execution MUST go through /base worker classes
- **ALLOWED**: Only in base/backend/workers/*.py worker implementations themselves
- **Correct approach**: Use GitCommandWorker for git operations, SystemCommandWorker for system commands (systemctl, loginctl, ssh-keygen, etc.); workers use FileSubprocessSync and shutil.which() for security; executable resolution at initialization

**Subprocess Partial Path**: `subprocess.run(["git", ...])`, `subprocess.run(["systemctl", ...])`  (S603/S607)
- **Example VIOLATION**:
  ```python
  subprocess.run(["git", "clone", url, dest])  # Partial path
  subprocess.run(["systemctl", "start", "service"])  # Partial path
  ```
- **Required fix**:
  ```python
  import shutil
  git_path = shutil.which("git")
  if git_path is None:
      raise RuntimeError("git not installed")
  subprocess.run([git_path, "clone", url, dest])
  ```
- **Better fix**: Use /base workers which handle this automatically
- **Correct approach**: Workers resolve absolute paths via shutil.which() at initialization; single subprocess execution point via FileSubprocessSync

**Hardcoded Temp Paths**: `Path("/tmp/...")` or `"/tmp/..."` (S108)
- **Example VIOLATION**:
  ```python
  test_file = Path("/tmp/test-file.txt")
  temp_dir = "/tmp/myapp"
  ```
- **Required fix**:
  ```python
  # In tests: use pytest tmp_path fixture
  def test_something(tmp_path):
      test_file = tmp_path / "test-file.txt"

  # In production code: use tempfile module
  import tempfile
  with tempfile.TemporaryDirectory() as temp_dir:
      temp_path = Path(temp_dir) / "myapp"
  ```
- **IMPORTANT**: Never hardcode /tmp paths; security risk (predictable paths, symlink attacks)
- **Correct approach**: Use pytest tmp_path/tmp_path_factory fixtures in tests; use tempfile.TemporaryDirectory/NamedTemporaryFile in production code

**Uncaught JSON Parse**: `data = json.loads(s)` - no try/except

**Assert-Only Validation**: `assert condition` - bypassed in optimized mode

**Exception → Test Skip**: `except e: if "substring" in str(e): pytest.skip()`

**Test Skipping**: `@pytest.mark.skip`, `pytest.skip()`, `unittest.skip()`, `self.skipTest()`
- **ZERO TOLERANCE** - tests must pass or fail, never skip
- **FIX**: Fix the issue or remove test

### MEDIUM

**Cleanup Suppression**: `try: session.close(); except: pass`

**Placeholder Before NotImplementedError**: `_ = var; raise NotImplementedError()`

**Implicit Defaults in Optional**: `field: Type|None = Field(default=value)`

**Wrong Exception Type**: `raise ValueError()` - should raise domain-specific

**Dict .get() Silent None**: `value = data.get("key")` - can't distinguish null from missing

**Implicit Defaults in Required**: `field: Type = default`

**Non-Empty __init__.py**: Imports, `__all__`, re-exports, code in `__init__.py`
- **ALLOWED**: Empty or comments/docstrings only

**Environment Implicit Default**: `os.environ.get("REQUIRED", "")` or `get("VAR", default)`

**Test Exception Without Assertion**: `with pytest.raises(Exception): op()` - no match= or assertion

**Test Validates Stub**: `assert stub_method() == expected_sentinel`

**Type Checker Config Suppression**: `ignore_missing_imports = True` or `exclude = pattern`

**Print in Production Code**: `print(...)` outside CLI entry points (T201)
- **Example VIOLATION**:
  ```python
  # In backend/service.py:
  def process_data(items):
      print(f"Processing {len(items)} items")  # VIOLATION
      return results
  ```
- **Required fix**:
  ```python
  from loguru import logger

  def process_data(items):
      logger.info(f"Processing {len(items)} items")
      return results
  ```
- **ALLOWED**: Only in CLI entry point scripts (scripts/*.py with `if __name__ == "__main__"`)
- **IMPORTANT**: Use logger for all non-CLI output; print() only for user-facing CLI output
- **Correct approach**: Use loguru logger for debug/info/warning/error; print() only in CLI argument parsers and output formatters

**Commented Code**: Code lines commented out instead of removed (ERA001)
- **Example VIOLATION**:
  ```python
  result = calculate()
  # old_result = legacy_calculate()  # VIOLATION
  # return old_result  # VIOLATION
  return result
  ```
- **Required fix**: Delete commented code, rely on git history
- **ALLOWED**: Inline explanatory comments (not commented-out code)
- **Correct approach**: Remove dead code; use git blame/log to recover if needed

**DateTime Parse → String**: `except ValueError: return value` - wrong type propagated

**Attribute Access or Operator**: `self.attr or default` - None/0/False masked

**Uncaught Type Conversion**: `value = float(input)` - should wrap and raise domain error

**JSON Parse → Fallback**: `except JSONDecodeError: data = {}`

## PERMITTED EXCEPTIONS (LIMITED)

**Cleanup in Finally**: `finally: with suppress(Exception): resource.close()`

**Documented "Returns None"**: `-> Config|None` with `"""Returns None if not found."""` docstring

**Test Fixtures**: `@pytest.fixture def empty_list(): return []`

**Not a Git Repo**: `except CalledProcessError as e: if "not a git repository" in e.stderr: return None; raise`
